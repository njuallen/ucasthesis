\chapter{引言}\label{chap:introduction}


\section{研究背景}

随着诸如Dennard Scaling和摩尔定律等传统工艺技术演进所带来的收益的大大减少，计算机体系结构有望进入创新的黄金时代。领域专用架构（DSA）是一种有前途的解决方案，可以继续提高计算性能，同时能向以前工艺演进一样，带来能量和面积效率水平的极大提升。不幸的是，传统的芯片设计方法和硬件开发方法需要大量的非经常性工程成本（NRE成本），包括工具，人工，IP和时间等。这极大提升了芯片设计的门槛，最终阻碍了DSA的广泛采用。

而与之相对应的是，由于开源软件的激增，过去几十年软件开发的大量工程成本和极长的设计周期已大大缩减。一个小型的软件开发团队现在可以针对他们自己的用户群体的需求，使用更高级的工具，迅速实现他们创新的想法。受到软件社区的启发，开放式的硬件设计被认为是降低芯片设计成本的最有前途的方法之一，受到了学术界和工业界的普遍关注。对于学术界来说，与开源软件模拟器（例如gem5，MARSSx86，Sniper或ZSim）相比，开源硬件实现具有许多优势。与软件模型不同，硬件实现可以演示精确的微体系结构行为，运行包含大量指令数的实际应用程序，并凭提供功率和面积测量结果。此外，开放式硬件实现还提供了一个基准平台，作为新微体系结构优化的baseline。对工业界来说，开放的硬件标准意味着他们可以共建共享复杂的软件或硬件生态，而不必被标准专利构筑的门槛拦在市场之外。开放的硬件实现，则可以降低了他们的IP开发成本，缩短设计周期。

最近一些年，涌现出了大量开源芯片设计的工作，开源芯片设计的生态逐渐繁荣。处理器核，cache，外设，加速器，SoC等，都有了开源的设计实现。我们以Chipyard SoC集成框架为例，展示开源芯片生态的现状。Chipyard是用于对硬件进行全系统的设计和评估的一套框架。它包含了一系列工具、库以及开源IP，可以将现有的开源芯片设计以及商业的芯片设计整合成一个完整的SoC。
Chipyard包含有以下IP和模块：

\begin{center}
    \begin{tabular}{lp{12cm}}
        \hline
			类别 & 项目/IP\\
        \hline
			处理器核 & RocketCore（顺序单发射处理器核），BOOM core（乱序多发射处理器核）\\
        \hline
			缓存 & Sifive BlockInclusiveCache，TLSimpleL2\\
        \hline
			多核 & Rocketchip（SoC框架）\\
        \hline
			加速器 & Hwacha（向量加速器），Gemmini：（脉动阵列生成器），NVLDA（AI推理加速器），SHA3 RoCC Accelerator（SHA3哈希算法加速器）\\
        \hline
			设备 & IceNet（NIC），UART，SPI Flash\\
        \hline
			片上网络 & Tilelink SEREES，Switch，Ring Network（NoC）\\
        \hline
    \end{tabular}
\end{center}

可以看出，开源的芯片设计种类基本齐全，使用开源的IP能够组成基本可用的SoC。但是开源IP仍然存在不少的问题，这使得他们更多是用于学术界的实验性流片，而没有在工业界得到广泛使用。开源IP相对于商业IP的劣势主要是在于如下的几个方面：

\begin{enumerate}
	\item 性能差，主要是指PPA（Power Performance，Area）上的差距。例如经我们评估Boom乱序处理器核只能0.9GHz，而商用的ARM乱序处理器核能达到2.8GHz的频率。
	\item 功能不齐全：开源的芯片设计只满足了基本的功能，而对于商用需要的更多功能，则没有实现。例如ECC等特性。
	\item 质量不可靠：开源芯片设计大都没有经过完善的验证，没有配套的验证环境，不满足流片必须的覆盖率质量指标。
\end{enumerate}

开源芯片设计距离高度可用，广泛使用，仍然有很多工作要做。本工作聚焦于缓存部分，希望能产出一款开源的，高度可用的（性能，功能，质量都达标的）的cache生成器，为开源生态的繁荣贡献一份力量。

问题：
1. 我感觉这里是应该想办法尽快切入到我做的内容：cache的
2. 同时对于我的工作，cache，到底是什么cache，我并没有说清楚，大家就不太明白

\section{研究动机}

\subsection{现有cache设计的不足}

尽管最近确实有一些开源的cache设计，但是它们没有一款同时做到了功能齐全，高性能以及高质量。我们将现有的开源cache实现列成了一个表如下，展示了它们的性能，功能性以及质量。
TLSimpleL2是最简单的L2/LLC设计，但是它不支持一致性，无法很好地支持多核。同时也没有支持流水化和多MSHR等特性，使得其吞吐率无法满足乱序核以及多核等高访存并发度的场景。
TLComplexL2对TLSimpleL2增强了延迟和吞吐，但是它依然不支持一致性，同时它也没有经过良好的验证，质量不可靠。
BlockInclusiveCache是Sifive开源的LLC设计，它是目前功能性、还有性能相对比较完善的一款cache设计。它支持一致性，但是它仅对上支持一致性，不对下支持一致性，使得其仅能被用作LLC，而不能被用作L2。
它支持流水化，多并发等基础特性，使得其延迟和吞吐能满足多核场景的需求，但是预取的缺失以及较低的频率，使得它无法用于高性能场景。同时，它也没有经过充分的验证。

问题：这里要不要把OpenSparc的cache也给算上呢？
\begin{table}[]
\begin{tabular}{|l|l|l|l|}
\hline
                                        & \textbf{TLSimpleL2} & \textbf{TLComplexL2} & \textbf{BlockInclusiveCache} \\ \hline
cache control                           & $\times$            & $\times$             & $\checkmark$                 \\ \hline
coherence                               & $\times$            & $\times$             & $\checkmark$                 \\ \hline
basic features（pipeline，MSHR）           & $\times$            & $\checkmark$         & $\checkmark$                 \\ \hline
advanced features（prefetch） & $\times$            & $\times$             & $\times$                     \\ \hline
frequency                               & 600MHz              & NA                   & 800MHz                       \\ \hline
verification                            & $\times$            & $\times$             & $\times$                     \\ \hline
taped out                               & $\checkmark$        & $\times$             & $\times$                     \\ \hline
\end{tabular}
\end{table}

总的来说，现有的开源cache仅能满足简单的，性能要求不高的场景的需求。
例如面向嵌入式场景，我们可以使用一个或若干个低访存需求的顺序核的，再使用现有的开源cache实现作为L2，组成一个低性能、低功耗的SoC。
但对于手机或者服务器端等高性能场景，往往是多个高访存需求的乱序核心，连接上多级层次化的缓存。高性能场景需要的是完整支持一致性的，层次化的，高性能（高带宽，高频率），质量可靠的cache实现。
而现有的开源cache实现无法满足需求。

\subsection{cache设计的挑战}

针对现有开源cache实现的不足，本工作试图设计设计实现一个高性能，高质量，开源的cache生成器，使其能满足高性能处理器的需求。设计实现一款cache生成器存在如下的诸多挑战：
问题：我这里实际上是列举了性能相关的所有方面吧，但它们都是挑战吗？不见得吗？到底哪些是真正的挑战呢？

第一个挑战是cache的性能。作为Cache，其性能指标主要是以下几个方面的：延迟，吞吐，频率和命中率。

问题：我感觉这个写在这里是不是太多了啊，可能要放到设计部分最好了吧？
我感觉延迟这里，可以只大致描述他们的挑战。然后具体的细节，取舍之类的，可以留到设计部分再去描述吧？

我们首先分析延迟。延迟是cache从接收一个请求到给出响应所花的周期数。由于请求有不同的类型（例如读或者写，缓存或者直通），相同类型的请求也可能会遇到不同的情况（例如cache命中，cache不命中），所以各个请求的延迟也不尽相同。而由于L2以及LLC等各级cache的命中率往往较高（需要数据支撑），同时与应用整体性能强相关的往往是读请求的延迟（因为load指令假如在L1 miss了，必须要从下级cache中取到数据，才能让后续依赖的指令发射执行。而store指令，如果在L1中miss了，它可以继续commit，不会影响后续指令的发射执行），所以我们一般需要将cache读命中的延迟尽可能地降低。又由于读命中的处理流程相当简单，只需要读tag和data，选出数据并返回给就可以了。在这么简单的处理流程中，最主要的部分就是对tag和data sram的读。而对于L2、L3这种大规模的cache，由于SRAM面积大，数量多，最终tag和data SRAM的读需要几拍与SRAM的后端布局有关。所以高性能cache要做到低延迟需要充分考虑结构以及后端的因素，这是设计实现上的关键挑战之一。

吞吐率是cache一段时间内能处理的请求的数量，吞吐量直接影响了核心的访存带宽以及访存并发度。对于乱序核以及多核等有高访存并发度，并需要高访存带宽的场景来说，cache系统的吞吐率在很大程序上影响了系统的性能。所以访存吞吐率也是性能优化的关键挑战。

频率则与cache性能正相关，频率越高，则cache性能越高。当生成的cache被用作L2这一层级的cache时，由于L2与核心紧耦合，为了提升性能，通常希望它与核心同频运行。假如L2与核心不同频运行，则会增大L1 miss的延迟，极大地影响性能。与此同时，在现代工艺下，L2面积往往非常大，以尽可能地提升命中率，因此提升cache频率，也是一个关键的挑战。

命中率也是cache的一个重要性能指标。根据量化上的公式，cache访问的平均延迟 = XX * XX，因此对于L3这种miss penalty非常高的cache，我们希望能有极高的命中率（Intel的L3命中率在XXX左右）。因此这也是一项关键挑战。

第二个挑战则是cache的质量。Cache设计实现存在大量的复杂性，它的复杂性体现在：

\begin{itemize}
	\item 复杂的功能：cache需要支持繁多的功能，例如支持一致性协议，cache请求，uncache请求，原子操作，预取替换，cache控制等。
	\item 复杂的请求处理流程：每个功能点对应的请求处理流程也很复杂，如图所示的例子。
	\item 复杂的性能优化：为了提升cache性能，cache设计上会做大量的性能优化，如流水化，多请求并行处理等。这会让设计实现进一步复杂化。
\end{itemize}

因此如何保证cache实现得正确无误，没有bug，是一项极大的挑战。

第三个挑战则是关于cache生成器的通用性与灵活性。作为一款cache生成器，我们希望它能根据我们的需求生成不同的cache。因此我们希望它具有一定的通用性和灵活性。
以现代高性能处理器为例： 现代高性能处理器中往往有多个层次的cache，L1，L2，L3，L4等。除L1与核心紧耦合，通常采用自定义的内部接口之外，其他cache层次，大多与核心松耦合，它们往往有相同的接口：上下都是标准的总线协议，同时有相似的功能与请求处理流程。因此我们希望能用同一份代码，不同的配置来生成除L1之外的所有缓存层次。这将极大地提升代码复用，降低开发成本。而与此同时，L2、L3、L4，不同层次的cache往往有不同的性能需求，怎样用同一份代码满足不同cache层次的性能需求，也将是一项很大的挑战。

\section{论文的主要内容和贡献}

针对前一章所述的高性能cache设计的挑战，本工作一方面借鉴了现有工作中成熟有效的设计，同时也提出了一些新的方法。在具体实现上，也针对性地做了许多细节的改进。

我的一点想法：
我感觉我们这个在设计上，可以把sifive的改一改，我们设计上就按照赵老师说的那个去说。
不过做的时候，我们还拿sifive的这个来测。我们把延迟和吞吐对齐就好了吧。
在实现的时候，我们可以说一下，我们这个和sifive的区别，改了多少就够了吧？

在性能方面，针对延迟，我们采用了将常用路径与非常用路径分开的设计，降低了常用路径的延迟。对于吞吐，我们使用了常见的多MSHR，非阻塞的设计。在频率方面，我们在设计上就结合后端进行了评估，具体工程实现上，也做了大量的时序优化工作。而对于命中率，我们则使用了先进的预取和替换算法。

在质量方面，我们基于UVM验证方法学设计实现了一套随机验证框架，对cache一致性的实现进行了充分的验证。

在灵活性方面，我们做了一系列的工程实现上的创新。基于一套架构设计，我们使关键资源，关键算法都做到了高度的可配置。一份代码，不同配置，即可满足不同的性能需求。

本工作设计实现了一款cache生成器：DeepDark，它是一款高性能，高质量，高灵活性的cache生成器，可以用作高性能处理器的缓存层次。
它的命中延迟为X拍，吞吐达到XXX，在SMIC 14nm工艺下，频率高达2.0GHz。同时它也经过了充分的验证，代码覆盖率，翻转覆盖率均达到XX%以上。


易难的意见，贡献这里总结得不够好，可以先写其他的，最后再总结。

总的来说，本工作做出了三点微小的贡献：

\begin{itemize}
	\item 高性能cache的设计与实现
	\item cache的验证
	\item 高度灵活性，高度可配置，具备高通用性的cache结构设计
\end{itemize}

\section{论文组织}

本文的后续章节组织结构如下：

第二章介绍了本工作所涉及到的一些工程技术方面的背景知识，包括Tilelink总线协议，芯片验证的基础知识以及业界常用的UVM验证方法学等。这部分背景知识补齐了一些技术细节，帮助读者更好地理解本工作设计、实现以及验证部分的内容。

第三章介绍了DeepDark cache生成器的设计，包括架构设计，在此架构设计下请求的处理流程以及一些性能优化。

第四章介绍了DeepDark的实现。首先介绍了本工作基于的code base以及选用的语言。 接下来介绍了实现上的一些重要细节，例如主要模块的结构，它们的流水级、状态机；重要的同步、一致性协议、transaction control等问题在实现上是如何解决的等。最后还介绍了一些重要算法的实现。

第五章介绍了DeepDark cache生成器的验证。包括了cache需要验证的功能，cache验证的难点，cache验证方案的设计和cache验证环境的实现。

第六章介绍了DeepDark的评估。首先介绍了评估实验的配置以及实验的方法论。然后对cache的性能，后端实现，验证等各方面进行了综合的评估，并给出了结果。

第六章对相关工作进行总结，并展望了下一步的研究方向。
